{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_-osPhX-hRR"
      },
      "source": [
        "# PREPARACIÓN PARA EL WEB SCRAPING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbhJT7xp_ZXo"
      },
      "source": [
        "### Instalación e importación de las librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3F8nysq5msOQ"
      },
      "outputs": [],
      "source": [
        "# Se instalan y se importan las librerías necesarias\n",
        "!pip install gspread\n",
        "!pip install pymongo\n",
        "!pip install instagrapi\n",
        "!pip install facebook-scraper\n",
        "import gspread\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "from facebook_scraper import get_posts\n",
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "from instagrapi import Client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qye_Omj5_hd3"
      },
      "source": [
        "### Extracción de los datos desde google sheets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "743KVSO8XsGp"
      },
      "outputs": [],
      "source": [
        "# Abrir documento de google sheets\n",
        "gc = gspread.service_account(filename='') # Archivo JSON descargado desde Google Sheets que permite realizar la conexión\n",
        "sh = gc.open_by_url('') # Url hacia el archivo de Google Sheets\n",
        "worksheet = sh.get_worksheet(0)\n",
        "records = worksheet.get_all_records() # Se guardan los datos de los clientes en la variable, en una forma de lista de diccionarios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj3QrEbGf62-"
      },
      "source": [
        "### Inicio de sesión en Facebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpuJ1x-wf2Pg"
      },
      "outputs": [],
      "source": [
        "# Se ingresa el correo y la contraseña de la cuenta de facebook que usaremos para scrapear\n",
        "user_fb = \"\" # Email\n",
        "pass_fb = \"\" # Contraseña\n",
        "credentials = (user_fb, pass_fb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyE5Fmcgd4Pr"
      },
      "source": [
        "### Inicio de sesión en Instagram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b-AIIKxX1Ai"
      },
      "outputs": [],
      "source": [
        "# Iniciar sesión en Instagram\n",
        "user_insta = \"\" # Username\n",
        "pass_insta = \"\" # Contraseña\n",
        "cl = Client()\n",
        "cl.login(user_insta, pass_insta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V-38CAvAb7J"
      },
      "source": [
        "# WEB SCRAPING\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFDHdu7vlp7Q"
      },
      "source": [
        "### Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoaaCtjrYKqU"
      },
      "outputs": [],
      "source": [
        "# Se generan patrones para extraer el username de los link de facebook e instagram\n",
        "patron_fb = r\"(?:facebook\\.com\\/|@)([a-zA-Z0-9._]+)\"\n",
        "patron_insta = r\"(?:instagram\\.com\\/|@)([a-zA-Z0-9._]+)\"\n",
        "\n",
        "# Se inicializa un ciclo for para cada cliente que hay en el google sheet\n",
        "for cliente in records:\n",
        "\n",
        "    # Se extrae el username del link de facebook del cliente\n",
        "    coincidencias_fb = re.findall(patron_fb, cliente['Link del Facebook de tu emprendimiento'])\n",
        "    if coincidencias_fb:\n",
        "        fb_username = coincidencias_fb[0] # ID de facebook del emprendimiento\n",
        "\n",
        "    # Se extrae el username del link de instagram del cliente\n",
        "    coincidencias_insta = re.findall(patron_insta, cliente['Link del Instagram de tu emprendimiento'])\n",
        "    if coincidencias_insta:\n",
        "        insta_username = coincidencias_insta[0] # ID de instagram del emprendimiento\n",
        "\n",
        "    # Se genera una excepción para scrapear los posts de facebook, si falla, lo vuelve a intentar,\n",
        "    # ya que se cierra la sesión después de un tiempo y avienta error al intentar iniciarla de nuevo, esto se resuelve intentandolo una segunda vez\n",
        "    try:\n",
        "        posts = get_posts(account=fb_username, pages=3, credentials=credentials) # Se ingresa el username, la cantidad de páginas (scrolleadas) que queremos scrapear\n",
        "                                                                                 # y las credenciales con las que iniciaremos sesión en la función get_posts\n",
        "    except:\n",
        "        posts = get_posts(account=fb_username, pages=3, credentials=credentials)\n",
        "        posts = [post for post in posts]\n",
        "    else:\n",
        "        posts = [post for post in posts]\n",
        "\n",
        "    # Si la función get_posts genera una lista vacia, significa que la página de facebook no existe,\n",
        "    # por lo que el resultado de las métricas pasa a ser \"N/A\"\n",
        "    if posts == []:\n",
        "        cliente['Fecha de la última publicación en Facebook'] = 'N/A'\n",
        "        cliente['Promedio de días entre publicaciones en Facebook'] = 'N/A'\n",
        "        cliente['Promedio de likes por publicación en Facebook'] = 'N/A'\n",
        "        cliente['Promedio de comentarios por publicación en Facebook'] = 'N/A'\n",
        "        cliente['Promedio de shares por publicación en Facebook'] = 'N/A'\n",
        "\n",
        "    # Si la página de facebook existe, se genera un ciclo for para extraer las métricas\n",
        "    else:\n",
        "\n",
        "        # Se generan listas vacías para guardar la cantidad de likes, comentarios, shares, fechas por post y una lista de diferencias entre las fechas de los posts\n",
        "        likes_fb = []\n",
        "        comments_fb = []\n",
        "        shares_fb = []\n",
        "        fechas_fb = []\n",
        "        diferencias_fb = []\n",
        "\n",
        "        # Se genera un ciclo for que ingresa los datos por post a las listas vacías anteriormente creadas\n",
        "        for i in posts:\n",
        "            likes_fb.append(i['likes'])\n",
        "            comments_fb.append(i['comments'])\n",
        "            shares_fb.append(i['shares'])\n",
        "            fechas_fb.append(i['time'])\n",
        "\n",
        "        fechas_fb = sorted(fechas_fb) # Se ordenan las fechas\n",
        "\n",
        "        # Se genera un ciclo for que ingresa la diferencia de días entre cada post a la lista vacía\n",
        "        for i in range(1, len(fechas_fb)):\n",
        "            diferencia_fb = (fechas_fb[i] - fechas_fb[i - 1]).days\n",
        "            diferencias_fb.append(diferencia_fb)\n",
        "\n",
        "        # Se generan las métricas a partir de los datos scrapeados\n",
        "        prom_frecuencia_fb = round(sum(diferencias_fb) / len(diferencias_fb), 2) # Promedio de las frecuencias entre los posts (mientras mas bajo, mejor)\n",
        "        prom_likes_fb = round(sum(likes_fb)/len(likes_fb), 2)                    # Promedio de cantidad de likes\n",
        "        prom_comments_fb = round(sum(comments_fb)/len(comments_fb), 2)           # Promedio de cantidad de comentarios\n",
        "        prom_shares_fb = round(sum(shares_fb)/len(shares_fb), 2)                 # Promedio de cantidad de shares\n",
        "        fecha_ult_publi_fb = posts[0]['time'].strftime(\"%d-%m-%Y\")               # Fecha de la publicación mas reciente\n",
        "\n",
        "        # Se añaden las métricas al diccionario del cliente\n",
        "        cliente['Fecha de la última publicación en Facebook'] = fecha_ult_publi_fb\n",
        "        cliente['Promedio de días entre publicaciones en Facebook'] = prom_frecuencia_fb\n",
        "        cliente['Promedio de likes por publicación en Facebook'] = prom_likes_fb\n",
        "        cliente['Promedio de comentarios por publicación en Facebook'] = prom_comments_fb\n",
        "        cliente['Promedio de shares por publicación en Facebook'] = prom_shares_fb\n",
        "\n",
        "    # Se genera una excepción para scrapear la información de instagram, si falla significa que el usuario de instagram no existe o que nos han baneado nuestra cuenta,\n",
        "    # por lo que el resultado de las métricas pasa a ser \"N/A\"\n",
        "    try:\n",
        "        cliente_insta_info = cl.user_info_by_username(insta_username).dict()\n",
        "    except:\n",
        "        cliente['Cantidad de seguidores en Instagram'] = 'N/A'\n",
        "        cliente['Cantidad de publicaciones en Instagram'] = 'N/A'\n",
        "        cliente['Fecha de la última publicación en Instagram'] = 'N/A'\n",
        "        cliente['Promedio de días entre publicaciones en Instagram'] = 'N/A'\n",
        "        cliente['Promedio de likes por publicación en Instagram'] = 'N/A'\n",
        "        cliente['Promedio de comentarios por publicación en Instagram'] = 'N/A'\n",
        "\n",
        "    # Si el usuario existe, se generan las métricas\n",
        "    else:\n",
        "        cant_posts_insta = cliente_insta_info['media_count']         # Cantidad de posts\n",
        "        cant_followers_insta = cliente_insta_info['follower_count']  # Cantidad de seguidores\n",
        "\n",
        "        cliente_insta_id = cl.user_info_by_username(insta_username).dict()['pk'] # ID de la página de instagram del cliente\n",
        "        cliente_insta_posts = cl.user_medias_v1(cliente_insta_id, amount=5)      # Se ingresa el ID de la página de instagram a scrapear y la cantidad de posts a scrapear\n",
        "\n",
        "        # Se generan listas vacías para guardar la cantidad de likes, comentarios, fechas por post y una lista de diferencias entre las fechas de los posts\n",
        "        likes_insta = []\n",
        "        comments_insta = []\n",
        "        fechas_insta = []\n",
        "        diferencias_insta = []\n",
        "\n",
        "        # Se genera un ciclo for que ingresa los datos por post a las listas vacías anteriormente creadas\n",
        "        for insta_post in cliente_insta_posts:\n",
        "            likes_insta.append(insta_post.dict()['like_count'])\n",
        "            comments_insta.append(insta_post.dict()['comment_count'])\n",
        "            fechas_insta.append(insta_post.dict()['taken_at'])\n",
        "\n",
        "        fechas_insta = sorted(fechas_insta) # Se ordenan las fechas\n",
        "\n",
        "        # Se genera un ciclo for que ingresa la diferencia de días entre cada post a la lista vacía\n",
        "        for i in range(1, len(fechas_insta)):\n",
        "            diferencia_insta = (fechas_insta[i] - fechas_insta[i - 1]).days\n",
        "            diferencias_insta.append(diferencia_insta)\n",
        "\n",
        "        # Se generan las métricas a partir de los datos scrapeados\n",
        "        prom_likes_insta = round(sum(likes_insta)/len(likes_insta), 2)                          # Promedio de cantidad de likes\n",
        "        prom_comments_insta = round(sum(comments_insta)/len(comments_insta), 2)                 # Promedio de cantidad de comentarios\n",
        "        prom_frecuencia_insta = round(sum(diferencias_insta) / len(diferencias_insta), 2)       # Promedio de las frecuencias entre los posts (mientras mas bajo, mejor)\n",
        "        fecha_ult_publi_insta = cliente_insta_posts[0].dict()['taken_at'].strftime(\"%d-%m-%Y\")  # Fecha de la publicación mas reciente\n",
        "\n",
        "        # Se añaden las métricas al diccionario del cliente\n",
        "        cliente['Cantidad de seguidores en Instagram'] = cant_followers_insta\n",
        "        cliente['Cantidad de publicaciones en Instagram'] = cant_posts_insta\n",
        "        cliente['Fecha de la última publicación en Instagram'] = fecha_ult_publi_insta\n",
        "        cliente['Promedio de días entre publicaciones en Instagram'] = prom_frecuencia_insta\n",
        "        cliente['Promedio de likes por publicación en Instagram'] = prom_likes_insta\n",
        "        cliente['Promedio de comentarios por publicación en Instagram'] = prom_comments_insta\n",
        "\n",
        "    print(cliente)\n",
        "\n",
        "    # Para evitar que baneen las cuentas de facebook e instagram, se pausa el ciclo for durante 30 mins, añadiendole de 1 a 15 mins extras aleatoriamente\n",
        "    tiempo_pausa_extra= random.uniform(60, 900)\n",
        "    time.sleep(1800 + tiempo_pausa_extra)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfBKSOFaeTKM"
      },
      "source": [
        "### Recomendaciones\n",
        "\n",
        "* Si el resultado de las métricas de Instagram del emprendimiento de algún cliente es \"N/A\" se trata de que esa página de Instagram no existe, si esto persiste con los siguientes clientes en la lista, se debe revisar la cuenta que se esté utilizando para scrapear, ya que probablemente ha sido baneada. La mayor cantidad de páginas que se lograron scrapear sin ser baneados fueron 27.\n",
        "* Se pueden probar distintos tiempos de pausa para ver cual es el mas conveniente para la cantidad de registros que se tienen, así también, para aumentar la cantidad de páginas que se logren scrapear sin ser baneados.\n",
        "* Se deberán crear cuentas de Instagram constantemente, probablemente una cada 2 días o las que sean necesarias. Igualmente si llegan a banear la cuenta de Facebook utilizada, se deberán crear más cuentas de Facebook.\n",
        "* Utilizar una VPN puede llegar a ser contradictorio ya que Facebook e Instagram detectan cuando el usuario está utilizando una VPN y lo marcan como actividad sospechosa. Al igual que no banean la IP del usuario, si no las cuentas, por lo tanto no sirve de mucho una VPN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcsIK24Rc91h"
      },
      "source": [
        "# MONGODB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ohlUT3Ndo-l"
      },
      "source": [
        "### Conexión con MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aj_BR3zDdhWO"
      },
      "outputs": [],
      "source": [
        "# Se debe iniciar sesion en MongoDB y añadir la dirección IP si es que lo pide.\n",
        "\n",
        "# Se genera la variable uri, en donde hay un usuario, una contraseña, y un cluster en donde ingresaremos los datos\n",
        "uri = \"\" # Esta variable se genera en MongoDB el la sección de \"Connect\"\n",
        "\n",
        "# Crear un nuevo cliente y conectar con el servidor\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "\n",
        "# Hacer un ping para confirmar la conexión\n",
        "try:\n",
        "    client.admin.command('ping')\n",
        "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w64DOJiKduEk"
      },
      "source": [
        "### Selección de base de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9IQw5FLdj6X"
      },
      "outputs": [],
      "source": [
        "# Seleccionar base de datos\n",
        "db = client[''] # Colocar base de datos\n",
        "collection = db[''] # Colocar colección"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FCjWSY9dx2A"
      },
      "source": [
        "### Inserción de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jwuqrzWb8sf"
      },
      "outputs": [],
      "source": [
        "# Se insertan los clientes a la base de datos en MongoDB\n",
        "for cliente in records:\n",
        "    collection.insert_one(cliente)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
